{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajir/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vajir/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/vajir/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vajir/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data set\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# train data info\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (42000, 784)\n",
      "Y_train shape = (42000,)\n",
      "X_test shape = (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.iloc[: ,1:].values/255.0\n",
    "Y_train = train_data.iloc[: ,0].values\n",
    "X_test = test_data.iloc[: ,:].values/255.0\n",
    "print('X_train shape =' ,X_train.shape)\n",
    "print('Y_train shape =' ,Y_train.shape)\n",
    "print('X_test shape =' ,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train ,num_classes =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(8400, 784)\n",
      "(33600, 10)\n",
      "(8400, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_std ,X_cv_std ,Y_train_std ,Y_cv_std = train_test_split(X_train ,Y_train ,test_size =0.2 ,random_state =0)\n",
    "print(X_train_std.shape)\n",
    "print(X_cv_std.shape)\n",
    "print(Y_train_std.shape)\n",
    "print(Y_cv_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512 ,activation= 'relu' ,input_shape =(784,)))\n",
    "network.add(layers.Dropout(0.4))\n",
    "network.add(layers.Dense(256 ,activation ='relu'))\n",
    "network.add(layers.Dropout(0.4))\n",
    "network.add(layers.Dense(64 ,activation ='relu'))\n",
    "network.add(layers.Dropout(0.4))\n",
    "network.add(layers.Dense(32 ,activation ='relu'))\n",
    "network.add(layers.Dense(10 ,activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 552,106\n",
      "Trainable params: 552,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer =optimizers.RMSprop(lr =2e-5) ,loss ='categorical_crossentropy' ,metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 36s 1ms/step - loss: 2.2148 - acc: 0.1858 - val_loss: 1.8997 - val_acc: 0.5646\n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 1.8622 - acc: 0.3753 - val_loss: 1.3781 - val_acc: 0.6733\n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 1.4979 - acc: 0.5117 - val_loss: 0.9952 - val_acc: 0.7606\n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 1.2376 - acc: 0.6030 - val_loss: 0.7704 - val_acc: 0.8139\n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 34s 997us/step - loss: 1.0532 - acc: 0.6656 - val_loss: 0.6331 - val_acc: 0.8490\n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 33s 986us/step - loss: 0.9223 - acc: 0.7103 - val_loss: 0.5441 - val_acc: 0.8673\n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 33s 978us/step - loss: 0.8197 - acc: 0.7462 - val_loss: 0.4795 - val_acc: 0.8810\n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 34s 1000us/step - loss: 0.7445 - acc: 0.7735 - val_loss: 0.4340 - val_acc: 0.8907\n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.6804 - acc: 0.7954 - val_loss: 0.3955 - val_acc: 0.8990\n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.6241 - acc: 0.8119 - val_loss: 0.3704 - val_acc: 0.9046\n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 33s 990us/step - loss: 0.5806 - acc: 0.8289 - val_loss: 0.3472 - val_acc: 0.9090\n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.5448 - acc: 0.8415 - val_loss: 0.3274 - val_acc: 0.9137\n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.5079 - acc: 0.8502 - val_loss: 0.3109 - val_acc: 0.9173\n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.4823 - acc: 0.8617 - val_loss: 0.2983 - val_acc: 0.9199\n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 33s 968us/step - loss: 0.4615 - acc: 0.8668 - val_loss: 0.2872 - val_acc: 0.9219\n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.4430 - acc: 0.8748 - val_loss: 0.2767 - val_acc: 0.9251\n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.4170 - acc: 0.8804 - val_loss: 0.2685 - val_acc: 0.9268\n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.3967 - acc: 0.8873 - val_loss: 0.2606 - val_acc: 0.9295\n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3917 - acc: 0.8893 - val_loss: 0.2546 - val_acc: 0.9305\n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3689 - acc: 0.8966 - val_loss: 0.2457 - val_acc: 0.9326\n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3599 - acc: 0.8990 - val_loss: 0.2405 - val_acc: 0.9344\n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3502 - acc: 0.9030 - val_loss: 0.2364 - val_acc: 0.9360\n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3363 - acc: 0.9046 - val_loss: 0.2290 - val_acc: 0.9382\n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.3285 - acc: 0.9107 - val_loss: 0.2249 - val_acc: 0.9389\n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.3161 - acc: 0.9120 - val_loss: 0.2212 - val_acc: 0.9405\n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.3118 - acc: 0.9136 - val_loss: 0.2143 - val_acc: 0.9418\n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.3032 - acc: 0.9165 - val_loss: 0.2121 - val_acc: 0.9421\n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2962 - acc: 0.9191 - val_loss: 0.2090 - val_acc: 0.9430\n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2849 - acc: 0.9218 - val_loss: 0.2034 - val_acc: 0.9446\n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 33s 994us/step - loss: 0.2782 - acc: 0.9236 - val_loss: 0.2017 - val_acc: 0.9446\n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.2735 - acc: 0.9259 - val_loss: 0.1969 - val_acc: 0.9456\n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2597 - acc: 0.9297 - val_loss: 0.1948 - val_acc: 0.9467\n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2623 - acc: 0.9280 - val_loss: 0.1913 - val_acc: 0.9473\n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 33s 988us/step - loss: 0.2540 - acc: 0.9310 - val_loss: 0.1885 - val_acc: 0.9482\n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.2486 - acc: 0.9313 - val_loss: 0.1874 - val_acc: 0.9489\n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 33s 975us/step - loss: 0.2420 - acc: 0.9343 - val_loss: 0.1830 - val_acc: 0.9499\n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 34s 998us/step - loss: 0.2392 - acc: 0.9343 - val_loss: 0.1811 - val_acc: 0.9508\n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2330 - acc: 0.9352 - val_loss: 0.1780 - val_acc: 0.9506\n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.2296 - acc: 0.9378 - val_loss: 0.1764 - val_acc: 0.9507\n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 33s 993us/step - loss: 0.2292 - acc: 0.9381 - val_loss: 0.1735 - val_acc: 0.9515\n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 33s 976us/step - loss: 0.2208 - acc: 0.9407 - val_loss: 0.1725 - val_acc: 0.9529\n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2176 - acc: 0.9414 - val_loss: 0.1710 - val_acc: 0.9546\n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.2126 - acc: 0.9422 - val_loss: 0.1667 - val_acc: 0.9551\n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 33s 994us/step - loss: 0.2094 - acc: 0.9438 - val_loss: 0.1651 - val_acc: 0.9562\n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.2059 - acc: 0.9446 - val_loss: 0.1649 - val_acc: 0.9558\n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 33s 995us/step - loss: 0.2024 - acc: 0.9458 - val_loss: 0.1621 - val_acc: 0.9562\n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 34s 1ms/step - loss: 0.1964 - acc: 0.9474 - val_loss: 0.1602 - val_acc: 0.9564\n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 37s 1ms/step - loss: 0.1954 - acc: 0.9472 - val_loss: 0.1596 - val_acc: 0.9571\n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 33s 990us/step - loss: 0.1924 - acc: 0.9485 - val_loss: 0.1574 - val_acc: 0.9576\n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 36s 1ms/step - loss: 0.1868 - acc: 0.9487 - val_loss: 0.1573 - val_acc: 0.9576\n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.1861 - acc: 0.9502 - val_loss: 0.1563 - val_acc: 0.9579\n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 36s 1ms/step - loss: 0.1804 - acc: 0.9499 - val_loss: 0.1534 - val_acc: 0.9589\n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 36s 1ms/step - loss: 0.1821 - acc: 0.9504 - val_loss: 0.1522 - val_acc: 0.9588\n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.1773 - acc: 0.9529 - val_loss: 0.1519 - val_acc: 0.9586\n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 39s 1ms/step - loss: 0.1759 - acc: 0.9524 - val_loss: 0.1508 - val_acc: 0.9590\n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1735 - acc: 0.9532 - val_loss: 0.1497 - val_acc: 0.9602\n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1716 - acc: 0.9557 - val_loss: 0.1486 - val_acc: 0.9595\n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1674 - acc: 0.9547 - val_loss: 0.1460 - val_acc: 0.9605\n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1651 - acc: 0.9568 - val_loss: 0.1459 - val_acc: 0.9614\n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1601 - acc: 0.9576 - val_loss: 0.1447 - val_acc: 0.9618\n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1600 - acc: 0.9566 - val_loss: 0.1444 - val_acc: 0.9626\n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1636 - acc: 0.9565 - val_loss: 0.1443 - val_acc: 0.9620\n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1560 - acc: 0.9585 - val_loss: 0.1437 - val_acc: 0.9624\n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 38s 1ms/step - loss: 0.1552 - acc: 0.9590 - val_loss: 0.1426 - val_acc: 0.9629\n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1535 - acc: 0.9594 - val_loss: 0.1411 - val_acc: 0.9625\n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1504 - acc: 0.9596 - val_loss: 0.1404 - val_acc: 0.9633\n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1449 - acc: 0.9615 - val_loss: 0.1406 - val_acc: 0.9635\n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1511 - acc: 0.9604 - val_loss: 0.1392 - val_acc: 0.9639\n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1459 - acc: 0.9610 - val_loss: 0.1398 - val_acc: 0.9635\n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1435 - acc: 0.9616 - val_loss: 0.1382 - val_acc: 0.9649\n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1402 - acc: 0.9623 - val_loss: 0.1377 - val_acc: 0.9649\n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1404 - acc: 0.9625 - val_loss: 0.1375 - val_acc: 0.9649\n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1398 - acc: 0.9628 - val_loss: 0.1360 - val_acc: 0.9658\n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1366 - acc: 0.9641 - val_loss: 0.1355 - val_acc: 0.9656\n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1369 - acc: 0.9644 - val_loss: 0.1366 - val_acc: 0.9657\n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1366 - acc: 0.9636 - val_loss: 0.1341 - val_acc: 0.9656\n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1310 - acc: 0.9653 - val_loss: 0.1339 - val_acc: 0.9663\n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1318 - acc: 0.9655 - val_loss: 0.1349 - val_acc: 0.9669\n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 39s 1ms/step - loss: 0.1301 - acc: 0.9656 - val_loss: 0.1325 - val_acc: 0.9670\n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1290 - acc: 0.9662 - val_loss: 0.1335 - val_acc: 0.9671\n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1270 - acc: 0.9669 - val_loss: 0.1318 - val_acc: 0.9682\n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1223 - acc: 0.9688 - val_loss: 0.1334 - val_acc: 0.9674\n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 43s 1ms/step - loss: 0.1212 - acc: 0.9682 - val_loss: 0.1321 - val_acc: 0.9685\n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1181 - acc: 0.9682 - val_loss: 0.1320 - val_acc: 0.9687\n",
      "Epoch 85/100\n",
      "33600/33600 [==============================] - 42s 1ms/step - loss: 0.1213 - acc: 0.9685 - val_loss: 0.1330 - val_acc: 0.9674\n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1219 - acc: 0.9693 - val_loss: 0.1314 - val_acc: 0.9679\n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 39s 1ms/step - loss: 0.1199 - acc: 0.9688 - val_loss: 0.1317 - val_acc: 0.9685\n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 41s 1ms/step - loss: 0.1140 - acc: 0.9701 - val_loss: 0.1315 - val_acc: 0.9683\n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1133 - acc: 0.9705 - val_loss: 0.1324 - val_acc: 0.9687\n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 37s 1ms/step - loss: 0.1121 - acc: 0.9709 - val_loss: 0.1307 - val_acc: 0.9685\n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 38s 1ms/step - loss: 0.1182 - acc: 0.9704 - val_loss: 0.1288 - val_acc: 0.9696\n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 38s 1ms/step - loss: 0.1108 - acc: 0.9703 - val_loss: 0.1298 - val_acc: 0.9693\n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 37s 1ms/step - loss: 0.1111 - acc: 0.9698 - val_loss: 0.1286 - val_acc: 0.9685\n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 38s 1ms/step - loss: 0.1097 - acc: 0.9718 - val_loss: 0.1282 - val_acc: 0.9685\n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 38s 1ms/step - loss: 0.1083 - acc: 0.9712 - val_loss: 0.1310 - val_acc: 0.9695\n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.1105 - acc: 0.9718 - val_loss: 0.1300 - val_acc: 0.9688\n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 40s 1ms/step - loss: 0.1101 - acc: 0.9720 - val_loss: 0.1284 - val_acc: 0.9701\n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 35s 1ms/step - loss: 0.1084 - acc: 0.9721 - val_loss: 0.1278 - val_acc: 0.9695\n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 33s 988us/step - loss: 0.1082 - acc: 0.9724 - val_loss: 0.1279 - val_acc: 0.9696\n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 33s 983us/step - loss: 0.1090 - acc: 0.9720 - val_loss: 0.1273 - val_acc: 0.9695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history =network.fit(X_train_std ,Y_train_std ,epochs =100 ,batch_size =64 ,validation_data =(X_cv_std ,Y_cv_std) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs =range(1 ,len((acc)) +1)\n",
    "plt.plot(epochs ,acc ,'bo' ,label ='training_accuracy')\n",
    "plt.plot(epochs ,val_acc ,'b-' ,label = 'validation_accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "Y_pred = np.argmax(y_pred ,axis =1)\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('sample_submission.csv')\n",
    "Y1 = data1.iloc[: ,0].values\n",
    "Y = {'ImageId':Y1 ,'Label':Y_pred}\n",
    "df = pd.DataFrame(data =Y ,dtype =int)\n",
    "df.to_csv('Data_recog_submission_5.csv' ,sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
